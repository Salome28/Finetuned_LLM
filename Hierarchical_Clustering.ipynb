{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import math"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class CAH :\n","\n","    def __init__(self,linkage_method = \"average\"):\n","        self.data = []\n","        self.linkage_method = linkage_method\n","        # le linkage_method est par défaut \"moyen\"\n","\n","    @staticmethod\n","    def tokenize(text: str, lang_in_English:str) -> list:\n","        \"\"\"\n","        Tokenize un texte\n","        arg1 = un texte\n","        entrée : un texte en français à tokeniser\n","        sortie : une liste de tokens\n","        \"\"\"\n","        # Importation du module nltk\n","        import nltk\n","\n","        # Téléchargement du tokenizer si ce n'est pas déjà fait\n","        # nltk.download('punkt')\n","\n","        # Tokenisation du texte en utilisant le tokenizer de nltk\n","        # La langue utilisée est déterminée par la variable lang_in_English et standarisé\n","        tokens = nltk.word_tokenize(text, language=lang_in_English.lower())\n","        # Les tokens sont convertis en minuscules et seuls les tokens alphanumériques sont conservés\n","        tokens = [token.lower() for token in tokens if token.isalnum()]\n","\n","        # Retourne la liste de tokens\n","        return tokens\n","\n","\n","\n","    @staticmethod\n","    def text2vec(text, lang_in_English: str) -> dict:\n","        \"\"\"\n","        Création d'un dictionnaire de vecteurs à partir d'un texte\n","        arg1 = texte à traiter\n","        entrée = un texte à vecteuriser\n","        sortie : dictionnaire de vecteurs\n","        \"\"\"\n","        # Importation du module nltk\n","        import nltk\n","        from nltk.corpus import stopwords\n","\n","        # Téléchargement des stopwords si nécessaire\n","        # nltk.download('stopwords')\n","\n","        # Création d'un ensemble de stopwords pour la langue spécifiée\n","        list_stopwords = set(stopwords.words(lang_in_English.lower()))\n","\n","        # Définition d'une fonction de filtrage qui supprime les stopwords du texte\n","        filtre_stopfr = lambda text: [token for token in text if token.lower() not in list_stopwords]\n","\n","        # Tokenisation et filtrage du texte en utilisant la méthode tokenize de l'objet CAH\n","        tokens = filtre_stopfr(CAH.tokenize(text, lang_in_English))\n","\n","        # Initialisation d'un dictionnaire vide pour stocker les vecteurs\n","        vector = {}\n","\n","        # Parcours de tous les tokens dans le texte\n","        for token in tokens:\n","            # Si le token est déjà présent dans le dictionnaire, incrémente son compteur\n","            if token in vector:\n","                vector[token] += 1\n","            # Sinon, ajoute le token au dictionnaire avec un compteur initialisé à 1\n","            else:\n","                vector[token] = 1\n","\n","        # Retourne le dictionnaire de vecteurs\n","        return vector\n","\n","\n","\n","    def url2text(self, list_urls: list) -> dict:\n","        \"\"\"\n","        Récupère le texte à partir d'une liste d'URLs\n","        \"\"\"\n","        # Importe le module requests pour effectuer des requêtes HTTP\n","        import requests\n","        # Importe BeautifulSoup pour analyser le contenu HTML\n","        from bs4 import BeautifulSoup\n","        # Importe la fonction unquote du module urllib.parse pour décoder les URL\n","        from urllib.parse import unquote\n","\n","        # Initialise un dictionnaire pour stocker les textes récupérés à partir des URLs\n","        textes = {}\n","\n","        # Pour chaque URL dans la liste des URLs fournies\n","        for url in list_urls:\n","            # Effectue une requête HTTP GET pour récupérer le contenu de l'URL\n","            response = requests.get(url)\n","            # Analyse le contenu HTML de la réponse\n","            parsed = BeautifulSoup(response.text, \"html.parser\")\n","            # Recherche tous les éléments <div> avec la classe 'mw-parser-output'\n","            text = parsed.find_all('div', class_='mw-parser-output')\n","\n","            # Vérifie s'il y a du texte trouvé dans la page Web\n","            if len(text):\n","                # Extrait la clé du texte en analysant l'URL que l'on utilisera comme \"label\" dans data\n","                key = url.split(\"/\")[-1]\n","                # On décode la clé URL pour traiter touts les caractère \"spéciaux\" de type éèä etc.\n","                key = unquote(key)\n","                # Stocke le texte trouvé dans le dictionnaire sous la clé décodée\n","                textes[key] = text[0].text\n","\n","        # Retourne le dictionnaire contenant les textes récupérés depuis les URLs\n","        return textes\n","\n","\n","    def add_texts(self, dict_urls: dict, lang_in_Englsih: str):\n","        \"\"\"\n","        Ajoute plusieurs textes à la liste de données\n","        Entrée : Dictionnaire de texte, une langue écrite en anglais\n","        Sortie : liste de dictionnaire pour chaque texte\n","        \"\"\"\n","        # Parcourt chaque paire clé-valeur dans le dictionnaire dict_urls\n","        for key, value in dict_urls.items():\n","            # Appelle la méthode add_text pour ajouter chaque texte à la liste de données\n","            # le label correspondra à la key (recupéré lors de urls2text) du dictionnaire dict_urls\n","            # il est important de mentionner toujours une langue que l'on utilise lors de la tokenisation dans text2vec\n","            self.add_text(key, value, lang_in_Englsih)\n","\n","        # Retourne la liste de données mise à jour après l'ajout des textes\n","        return self.data\n","\n","    def add_text(self,label,text,lang_in_English:str) :\n","        \"\"\"\n","        Ajoute un texte à data\n","        Entrée : un label, un texte et une langue écrite en anglais (pour que le tokenizer\n","        applique les bonnes méthodes)\n","        \"\"\"\n","        # On ajoute à data un dictionnaire avec le label donné en argument\n","        # la valeur de vecteur est le resultat du text2vec du text donné comme argument\n","        self.data.append({\"label\" : label, \"vector\" : CAH.text2vec(text,lang_in_English)})\n","\n","    def del_text(self,label:str) :\n","        \"\"\"\n","        Supprime le texte correspondant au label\n","        \"\"\"\n","        # on retire le texte à partir du label donnée en argument \n","        # en recréant une nouvelle liste data sans les informations associées au label donné\n","        self.data = [item for item in self.data if item[\"label\"] != label]\n","        return (f'Le text {label} a été supprimé')\n","\n","    def sim_cosinus(vect1:dict, vect2: dict):\n","               \n","        \"\"\"\n","        Calcul le cosinus de deux vecteurs\n","        vect1: premier vecteur de fréquence, vect2: deuxième vecteur de fréquence\n","        retour : float correspondant au cosinus\n","        \"\"\"\n","        # on initialise 3 variables (produit scalaire et normes des deux vecteurs) que l'on met à 0.\n","        produit_scalaire=0\n","        norme_v1=0\n","        norme_v2=0\n","        # on fait une boucle sur les clés du vecteur 1\n","        for mot in vect1.keys():\n","            # est ce que le mot dans le vect1 est dans le vecteur 2\n","            if mot in vect2:\n","                # si oui on calcule le produit scalaire avec les fréquences du mot que l'on multiplie\n","                produit_scalaire+=vect1[mot]*vect2[mot]\n","\n","        # on calcule les normes des deux vecteurs\n","        norme_v1=math.sqrt(sum(freq**2 for freq in vect1.values()))\n","        norme_v2=math.sqrt(sum(freq**2 for freq in vect2.values()))\n","\n","        # important de préciser que les normes doivent être différentes de 0 sinon on aura une erreur du fait\n","        # que la division par 0 est impossible\n","        if norme_v1!=0 and norme_v2!=0:\n","            cosinus=produit_scalaire / (norme_v1*norme_v2)\n","        # si une des normes est égale à 0 cela veut dire que l'on divise par 0, ce qui est impossible, on donne donc la valeur 0 au cosinus\n","        else:\n","            cosinus=0.0\n","\n","        return cosinus\n","\n","    def _dissim(self,cluster1: list, cluster2:list):\n","        \"\"\"\n","        Fonction qui calcule la dissimilarité entre 2 clusters\n","        cluster1 : premier cluster\n","        cluster2: deuxième cluster\n","        retour: on renvoie un float qui est la dissimilarité des deux clusters\n","        \"\"\"\n","\n","        # on initialise une liste (tableau) pour le calcul de la matrice de distance\n","        similarites = []\n","\n","        #les clusters sont de la forme suivante du data\n","        # pour chaque élément du cluster 1\n","        for i1 in cluster1:\n","            # pour chaque élément du cluster 2\n","            for i2 in cluster2:\n","              # on calcule le cosinus contenu le dictionnaire \"vector\" que l'on met dans le tableau des similarités\n","              similarites.append(CAH.sim_cosinus(self.data[i1][\"vector\"],self.data[i2][\"vector\"]))\n","\n","        #on calcule la dissimilarité avec 1 - la moyenne des similarités\n","        if similarites:\n","            dissimilarite= 1 - sum(similarites)/len(similarites)\n","        else:\n","            dissimilarite=1\n","\n","        # on retourne la dissimilarite entre les deux clusters\n","        return dissimilarite\n","\n","    def classify(self,n,min_sim)-> list :\n","        \"\"\"\n","        Fonction qui effectue le calcul de classification hierarchique\n","        n : entier qui correspond au nombre de cluster final que l'on veut avoir\n","        min_sim : float qui correspond à la similarité minimale que l'on veut atteindre\n","\n","        \"\"\"\n","\n","        # création d'une liste de clusters qui contient le nombre de documents dans data (les documents seront représentés\n","        # avec leurs indices respectifs)\n","        clusters = [[i] for i in range(len(self.data))]\n","\n","        # On veut s'arrêter quand le nombre d'éléments dans clusters est égal à n\n","        while len(clusters)>n:\n","\n","            # on initialise le minimum avec un nombre infini\n","            min_dissimilarity = float('inf')\n","\n","            # on enregistre les indices des clusters à fusionner\n","            ind_clusters=None\n","\n","            # on fait deux boucles imbriquées avec deux indices différents (i et j) pour pouvoir comparer\n","            # les clusters 2 à 2\n","            for i in (range(len(clusters)-1)):\n","                for j in (range(i+1,len(clusters))):\n","\n","                    # on calcule la dissimilarité entre les deux clusters i et j\n","                    dissim=self._dissim(clusters[i],clusters[j])\n","\n","                    # comparaison de la dissimilarité avec le minimum\n","                    if dissim < min_dissimilarity:\n","                        # on remplace le minimum si la dissimlarité est inférieure à ce dernier\n","                        min_dissimilarity = dissim\n","                        # on stocke les indices des clusters à fusionner\n","                        ind_clusters=(i,j)\n","\n","            # si la dissimilarité minimale est supérieure à la similarité minimale spécifiée\n","            if min_dissimilarity >= min_sim:\n","                # on arrête la classification\n","                break\n","\n","            # fusion des clusters avec les indices stockés\n","            i, j = ind_clusters\n","            clusters[j] += clusters[i]\n","            clusters.pop(i)\n","            \n","        while len(clusters) > n:\n","          # Fusionner les deux premiers clusters dans une liste temporaire\n","          temp_cluster = clusters[0] + clusters[1]\n","          #Retirer les deux premiers clusters de la liste\n","          clusters = clusters[2:]\n","          # Ajouter le nouveau cluster fusionné à la liste\n","          clusters.insert(0, temp_cluster)\n","            \n","        # on retourne la liste des nouveaux clusters\n","        return clusters\n","    \n","    #Fonction bonus\n","\n","    # Fonction qui renvoie un dictionnaire contenant les term frequency de chaque terme\n","    def tf(self):\n","        \"\"\"\n","        Cette fonction calcule le Term Frequency qui est égal au rapport entre le nombre d'occurences du terme\n","        dans le document sur le nombre total de termes dans le document.\n","        retour : dictionnaire avec comme clé les termes des documents et les valeurs sont les tf associés.\n","        \"\"\"\n","\n","        # on initisalise un dictionnaire à renvoyer avec les valeurs des tf\n","        tf_values={}\n","\n","        # on parcourt chaque document du data\n","        for doc in self.data:\n","            # le nombre total de termes dans le document est égal à la longueurs des vecteurs de chaque document\n","            nb_termes=len(doc[\"vector\"].values())\n","            # on range les tf dans un dictionnaire pour chaque document\n","            tf_doc={}\n","            # on parcourt les tokens et les fréquences dans le dictionnaire \"vecteur\"\n","            for terme,freq in doc[\"vector\"].items():\n","                # calcule le nombre d'occurence du terme sur le nombre totale de tokens et on le range dans le dictionnaire\n","                tf_doc[terme]=freq /nb_termes\n","\n","            # on met la valeur du tf dans le dictionnaire tf_values\n","            tf_values[doc[\"label\"]]=tf_doc\n","\n","            return tf_values\n","\n","    # Fonction qui renvoie un dictionnaire contenant l'Inverse Document Frequency de chaque token.\n","    def idf(self):\n","        \"\"\"\n","        Cette fonction calcule le Inverse Document Frequency qui est égal au log du rapport du nombre total de documents sur le nombre de documents contenant le terme\n","        Retour : dictionnaire qui contient les clés : les mots des documents et les valeurs correspondant aux idf associés.\n","        \"\"\"\n","\n","        # le nombre de documents est égal à la longueur de notre liste data\n","        nb_documents=len(self.data)\n","\n","        # on initialise un dictionnaire qui prendre comme clé chaque terme et qui aura comme valeur le nombre de document\n","        # dans lequel le terme apparait\n","        termes_doc={}\n","\n","        # on fait un parcours des documents dans data\n","        for doc in self.data:\n","            # on parcours chaque terme dans le dictionnaire \"vector\"\n","            for terme in doc[\"vector\"]:\n","                # si on trouve le terme dans le document\n","                if terme in termes_doc:\n","                    # on incrémente la valeur des fréquences de document pour le terme\n","                    termes_doc[terme]=termes_doc[terme]+1\n","                else:\n","                    # sinon on initialise la valeur à 1 pour chaque terme\n","                    termes_doc[terme]=1\n","\n","        # on initialise un dictionnaire pour mettre les valeurs idf pour chaque terme\n","        idf_values={}\n","        # on parcourt le dictionnaire terme_doc et on associe pour chaque le terme le nb_documents_contenant_terme\n","        for terme, nb_documents_contenant_terme in termes_doc.items():\n","            # on calcule la valeur idf pour chaque terme : log (nb_documents/nb_documents_contenant_terme)\n","            idf_values[terme] = math.log(nb_documents / (nb_documents_contenant_terme))\n","\n","        return idf_values\n","\n","    def tf_idf(self):\n","        \"\"\"\n","        Calcule le TF-IDF pour chaque terme dans chaque document.\n","        Renvoie un dictionnaire contenant les TF-IDF de chaque terme pour chaque document.\n","        \"\"\"\n","        # On récupère les résultats de la fonction tf\n","        tf_values = self.tf()\n","        # On récupère les résultats de la fonction idf\n","        idf_values = self.idf()\n","        # On initialise un dictionnaire pour stocker les TF-IDF\n","        tf_idf_values = {}\n","\n","        # On parcourt chaque document dans les résultats de tf\n","        for doc_label, terme_tf_values in tf_values.items():\n","            # On initialise un dictionnaire pour stocker les TF-IDF du document actuel\n","            doc_tf_idf = {}\n","\n","            # On parcourt chaque terme et sa fréquence dans les résultats de tf pour le document actuel\n","            for terme, terme_freq in terme_tf_values.items():\n","                # On calcule le TF-IDF pour le terme actuel en multipliant le TF par l'IDF\n","                terme_tf_idf = terme_freq * idf_values.get(terme, 0)  # Si le terme n'existe pas dans idf_values, utilise 0 comme IDF\n","                # On stocke le TF-IDF calculé pour le terme actuel dans le dictionnaire du document\n","                doc_tf_idf[terme] = terme_tf_idf\n","\n","            # On ajoute les TF-IDF du document actuel au dictionnaire global\n","            tf_idf_values[doc_label] = doc_tf_idf\n","\n","        return tf_idf_values\n"]},{"cell_type":"markdown","metadata":{},"source":["# Données d'entraînement\n","\n","Voici quelques données d'entrainements. \n","Nous avons choisi d'utiliser des pages Wikipédia de nouvelles de Sherlock Holmes. Il est important pour le bon fonctionnement de l'algorithme que les urls soit mis sous la forme d'une liste d'urls. "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/salomenkb/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[[0], [1], [3, 2]]\n"]},{"data":{"text/plain":["'Le text Le_Mystere_du_Val_Boscombe a été supprimé'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["urls = [\n","    \"https://fr.wikipedia.org/wiki/Un_scandale_en_Boh%C3%AAme\",\n","    \"https://fr.wikipedia.org/wiki/La_Ligue_des_rouquins\",\n","    \"https://fr.wikipedia.org/wiki/Une_affaire_d%27identit%C3%A9\",\n","    \"https://fr.wikipedia.org/wiki/Le_Myst%C3%A8re_du_Val_Boscombe\",\n","]\n","\n","# On définit l'objet Sherlock\n","sherlock = CAH()\n","# On génère un dictoinnaire avec le contenu des urls\n","sherlock_livres = sherlock.url2text(urls)\n","# On ajoute à notre objet les textes du dictoinnaire sherlock_livres\n","# En précisant la langue des textes\n","sherlock.add_texts(sherlock_livres,\"French\")\n","# Puis nous classifions les données des histoires de SH\n","print(sherlock.classify(3,2.5))\n","\n","# On peut aussi supprimer des textes \n","sherlock.del_text(\"Le_Mystere_du_Val_Boscombe\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["{'Un_scandale_en_Bohême': {'articles': 0.0,\n","  'homonymes': 0.0018607978001609269,\n","  'voir': 0.0,\n","  'a': 0.0,\n","  'scandal': 0.011164786800965562,\n","  'in': 0.011164786800965562,\n","  'bohemia': 0.009303989000804634,\n","  'scandale': 0.0,\n","  'bohême': 0.0,\n","  'illustration': 0.0003861504328211823,\n","  'sidney': 0.0,\n","  'paget': 0.0,\n","  '1891': 0.0,\n","  'publication': 0.0,\n","  'auteur': 0.0,\n","  'arthur': 0.0,\n","  'conan': 0.0,\n","  'doyle': 0.0,\n","  'titre': 0.0,\n","  'langue': 0.0,\n","  'anglais': 0.0,\n","  'parution': 0.0,\n","  'juillet': 0.0027911967002413906,\n","  'strand': 0.0,\n","  'magazine': 0.0,\n","  'mensuel': 0.0,\n","  'recueil': 0.0,\n","  'aventures': 0.0,\n","  'sherlock': 0.0,\n","  'holmes': 0.0,\n","  'intrigue': 0.0,\n","  'date': 0.0,\n","  'fictive': 0.0,\n","  'mars': 0.005582393400482781,\n","  '1888': 0.001158451298463547,\n","  '1': 0.0,\n","  'personnages': 0.0,\n","  'holmesdocteur': 0.0,\n","  'watsonsire': 0.0018607978001609269,\n","  'von': 0.007443191200643707,\n","  'ormstein': 0.005582393400482781,\n","  'client': 0.0018607978001609269,\n","  'irène': 0.01860797800160927,\n","  'adlergodfrey': 0.0018607978001609269,\n","  'norton': 0.011164786800965562,\n","  'nouvelle': 0.0,\n","  'ligue': 0.0,\n","  'rouquins': 0.0,\n","  'modifier': 0.0,\n","  'première': 0.0,\n","  '56': 0.0037215956003218537,\n","  'nouvelles': 0.0,\n","  'écrites': 0.0018607978001609269,\n","  'sir': 0.0,\n","  'bien': 0.0027911967002413906,\n","  'aventure': 0.0009303989000804634,\n","  'détective': 0.007723008656423646,\n","  'londonien': 0.0018607978001609269,\n","  'puisque': 0.0018607978001609269,\n","  'déjà': 0.0018607978001609269,\n","  'publié': 0.0037215956003218537,\n","  'deux': 0.005582393400482781,\n","  'romans': 0.0018607978001609269,\n","  '1887': 0.0018607978001609269,\n","  '1890': 0.0009303989000804634,\n","  'mettant': 0.0003861504328211823,\n","  'scène': 0.001158451298463547,\n","  'personnage': 0.0027911967002413906,\n","  'étude': 0.0,\n","  'rouge': 0.0,\n","  'signe': 0.0,\n","  'quatre': 0.0,\n","  'publiée': 0.0009303989000804634,\n","  'fois': 0.0007723008656423646,\n","  'cette': 0.004651994500402317,\n","  'republiée': 0.0018607978001609269,\n","  'dès': 0.0037215956003218537,\n","  '1892': 0.0,\n","  '12': 0.0018607978001609269,\n","  'intitulé': 0.0037215956003218537,\n","  'constitue': 0.005582393400482781,\n","  'trame': 0.0018607978001609269,\n","  'code': 0.0,\n","  'situation': 0.0018607978001609269,\n","  'initiale': 0.0018607978001609269,\n","  'dévoilant': 0.0018607978001609269,\n","  'identité': 0.0009303989000804634,\n","  'watson': 0.005792256492317735,\n","  'jetant': 0.0018607978001609269,\n","  'terre': 0.009303989000804634,\n","  'masque': 0.0037215956003218537,\n","  'dessin': 0.0037215956003218537,\n","  '20': 0.0037215956003218537,\n","  'docteur': 0.005582393400482781,\n","  'rend': 0.0009303989000804634,\n","  '221b': 0.0037215956003218537,\n","  'baker': 0.014886382401287415,\n","  'street': 0.007443191200643707,\n","  'revoir': 0.0018607978001609269,\n","  'ancien': 0.0009303989000804634,\n","  'colocataire': 0.0018607978001609269,\n","  'montre': 0.0037215956003218537,\n","  'mystérieuse': 0.0018607978001609269,\n","  'lettre': 0.007443191200643707,\n","  'reçue': 0.0018607978001609269,\n","  'journée': 0.0018607978001609269,\n","  'non': 0.005582393400482781,\n","  'datée': 0.0018607978001609269,\n","  'signée': 0.0037215956003218537,\n","  'annonce': 0.0009303989000804634,\n","  'venue': 0.0037215956003218537,\n","  'inconnu': 0.0018607978001609269,\n","  'consultation': 0.0018607978001609269,\n","  'confidentielle': 0.0018607978001609269,\n","  'préserver': 0.0018607978001609269,\n","  'anonymat': 0.0018607978001609269,\n","  'visiteur': 0.007443191200643707,\n","  'viendra': 0.0018607978001609269,\n","  'masqué': 0.0037215956003218537,\n","  'certains': 0.0018607978001609269,\n","  'détails': 0.0018607978001609269,\n","  'permettent': 0.0037215956003218537,\n","  'déduire': 0.0018607978001609269,\n","  'missive': 0.0018607978001609269,\n","  'provient': 0.0018607978001609269,\n","  'personne': 0.0027911967002413906,\n","  'aisée': 0.0018607978001609269,\n","  'germanophone': 0.0018607978001609269,\n","  'probablement': 0.0018607978001609269,\n","  'originaire': 0.0018607978001609269,\n","  'royaume': 0.0018607978001609269,\n","  'arrive': 0.005582393400482781,\n","  'demande': 0.0027911967002413906,\n","  'rester': 0.0018607978001609269,\n","  'assister': 0.0018607978001609269,\n","  'entre': 0.004651994500402317,\n","  'déclare': 0.0018607978001609269,\n","  'être': 0.00837359010072417,\n","  'comte': 0.0018607978001609269,\n","  'kramm': 0.0018607978001609269,\n","  'gentilhomme': 0.0018607978001609269,\n","  'dupe': 0.0018607978001609269,\n","  'divers': 0.0018607978001609269,\n","  'indices': 0.0037215956003218537,\n","  'comprendre': 0.0018607978001609269,\n","  'fait': 0.0,\n","  'face': 0.0037215956003218537,\n","  'roi': 0.014886382401287415,\n","  'wilhelm': 0.0018607978001609269,\n","  'gottreich': 0.0018607978001609269,\n","  'sigismond': 0.0018607978001609269,\n","  'décontenancé': 0.0018607978001609269,\n","  'perspicacité': 0.0037215956003218537,\n","  'jette': 0.0037215956003218537,\n","  'explique': 0.007443191200643707,\n","  'raisons': 0.0018607978001609269,\n","  'cinq': 0.0,\n","  'ans': 0.0018607978001609269,\n","  'auparavant': 0.0009303989000804634,\n","  'encore': 0.0037215956003218537,\n","  'monarque': 0.0018607978001609269,\n","  'connaissance': 0.0018607978001609269,\n","  'adler': 0.027911967002413902,\n","  'jeune': 0.0027030530297482763,\n","  'cantatrice': 0.0018607978001609269,\n","  'britannique': 0.0,\n","  'noué': 0.0018607978001609269,\n","  'relation': 0.0037215956003218537,\n","  'sentimentale': 0.0018607978001609269,\n","  'femme': 0.00837359010072417,\n","  'vit': 0.0018607978001609269,\n","  'toujours': 0.0009303989000804634,\n","  'londres': 0.0009303989000804634,\n","  'possède': 0.0018607978001609269,\n","  'photographie': 0.01860797800160927,\n","  'couple': 0.0018607978001609269,\n","  'illégitime': 0.0037215956003218537,\n","  'menace': 0.0037215956003218537,\n","  'rendre': 0.007443191200643707,\n","  'publique': 0.0037215956003218537,\n","  'lors': 0.0018607978001609269,\n","  'fiançailles': 0.0018607978001609269,\n","  'clotilde': 0.0018607978001609269,\n","  'othman': 0.0018607978001609269,\n","  'princesse': 0.0018607978001609269,\n","  'scandinavie': 0.0018607978001609269,\n","  'motivation': 0.0018607978001609269,\n","  'nuire': 0.0018607978001609269,\n","  'semble': 0.0037215956003218537,\n","  'jalousie': 0.0018607978001609269,\n","  'familles': 0.0018607978001609269,\n","  'royales': 0.0018607978001609269,\n","  'doit': 0.0027911967002413906,\n","  'annoncée': 0.0018607978001609269,\n","  'trois': 0.005582393400482781,\n","  'jours': 0.0018607978001609269,\n","  'diplomatique': 0.0018607978001609269,\n","  'absolument': 0.0018607978001609269,\n","  'évité': 0.0018607978001609269,\n","  'compromettante': 0.0037215956003218537,\n","  'rétribue': 0.0018607978001609269,\n","  'somme': 0.0003861504328211823,\n","  '300': 0.0018607978001609269,\n","  'livres': 0.0009303989000804634,\n","  'sterling': 0.0018607978001609269,\n","  'or': 0.0037215956003218537,\n","  '700': 0.0018607978001609269,\n","  'billets': 0.0018607978001609269,\n","  'enquête': 0.005582393400482781,\n","  'mariage': 0.007443191200643707,\n","  'godfrey': 0.007443191200643707,\n","  'compte': 0.0018607978001609269,\n","  'démarrer': 0.0018607978001609269,\n","  'seul': 0.0037215956003218537,\n","  'lendemain': 0.007443191200643707,\n","  'matin': 0.0037215956003218537,\n","  'donne': 0.0037215956003218537,\n","  'heures': 0.0018607978001609269,\n","  'présent': 0.0037215956003218537,\n","  'dite': 0.0018607978001609269,\n","  'retard': 0.0018607978001609269,\n","  'grimé': 0.0018607978001609269,\n","  'valet': 0.0018607978001609269,\n","  'après': 0.0009303989000804634,\n","  'avoir': 0.005582393400482781,\n","  'quitté': 0.0037215956003218537,\n","  'costume': 0.0037215956003218537,\n","  'éclate': 0.0037215956003218537,\n","  'rire': 0.0018607978001609269,\n","  'résume': 0.0018607978001609269,\n","  'péripéties': 0.0018607978001609269,\n","  'matinée': 0.0018607978001609269,\n","  'rendu': 0.0018607978001609269,\n","  'abords': 0.0018607978001609269,\n","  'briony': 0.007443191200643707,\n","  'lodge': 0.007443191200643707,\n","  'résidence': 0.0018607978001609269,\n","  'apprendre': 0.0018607978001609269,\n","  'informations': 0.0009303989000804634,\n","  'habitudes': 0.0018607978001609269,\n","  'auprès': 0.0018607978001609269,\n","  'cochers': 0.0018607978001609269,\n","  'quartier': 0.0018607978001609269,\n","  'ainsi': 0.0037215956003218537,\n","  'appris': 0.0018607978001609269,\n","  'dénommé': 0.0018607978001609269,\n","  'venait': 0.0018607978001609269,\n","  'régulièrement': 0.0018607978001609269,\n","  'visite': 0.0018607978001609269,\n","  'dont': 0.004651994500402317,\n","  'acte': 0.0018607978001609269,\n","  'soudainement': 0.0018607978001609269,\n","  'arrivé': 0.0018607978001609269,\n","  'villa': 0.0037215956003218537,\n","  'puis': 0.007443191200643707,\n","  'reparti': 0.0018607978001609269,\n","  'manière': 0.005582393400482781,\n","  'précipitée': 0.0018607978001609269,\n","  'fiacre': 0.0037215956003218537,\n","  'suivi': 0.0037215956003218537,\n","  'véhicule': 0.0037215956003218537,\n","  'privé': 0.0018607978001609269,\n","  'entendu': 0.0018607978001609269,\n","  'donner': 0.0037215956003218537,\n","  'conducteur': 0.0018607978001609269,\n","  'sans': 0.004651994500402317,\n","  'attendre': 0.0018607978001609269,\n","  'monté': 0.0018607978001609269,\n","  'lieu': 0.0018607978001609269,\n","  'dit': 0.0018607978001609269,\n","  'flânant': 0.0018607978001609269,\n","  'faisant': 0.0009303989000804634,\n","  'passer': 0.0018607978001609269,\n","  'simple': 0.0009303989000804634,\n","  'assisté': 0.0037215956003218537,\n","  'cérémonie': 0.0018607978001609269,\n","  'expéditive': 0.0018607978001609269,\n","  'jeunes': 0.0018607978001609269,\n","  'personnes': 0.0018607978001609269,\n","  'poursuivies': 0.0018607978001609269,\n","  'témoins': 0.0018607978001609269,\n","  'puisse': 0.0018607978001609269,\n","  'prononcé': 0.0018607978001609269,\n","  'demandé': 0.0018607978001609269,\n","  'homme': 0.0027911967002413906,\n","  'place': 0.0018607978001609269,\n","  'remplir': 0.0018607978001609269,\n","  'rôle': 0.0015446017312847292,\n","  'devenu': 0.0018607978001609269,\n","  'témoin': 0.0018607978001609269,\n","  'inattendue': 0.0018607978001609269,\n","  'costumé': 0.0037215956003218537,\n","  'clergyman': 0.005582393400482781,\n","  'considère': 0.0018607978001609269,\n","  'laquelle': 0.0018607978001609269,\n","  'réduit': 0.0018607978001609269,\n","  'priori': 0.0018607978001609269,\n","  'si': 0.0018607978001609269,\n","  'désormais': 0.0037215956003218537,\n","  'mariée': 0.0018607978001609269,\n","  'plus': 0.0009303989000804634,\n","  'intérêt': 0.0018607978001609269,\n","  'révéler': 0.005582393400482781,\n","  'ancienne': 0.0018607978001609269,\n","  'néanmoins': 0.0018607978001609269,\n","  'récupérée': 0.0018607978001609269,\n","  'mission': 0.0009303989000804634,\n","  'menée': 0.0018607978001609269,\n","  'sait': 0.0018607978001609269,\n","  'devrait': 0.0018607978001609269,\n","  'rentrer': 0.0018607978001609269,\n","  'chez': 0.011164786800965562,\n","  'vers': 0.0037215956003218537,\n","  'sept': 0.0018607978001609269,\n","  'soir': 0.0018607978001609269,\n","  'décide': 0.0009303989000804634,\n","  'monter': 0.0018607978001609269,\n","  'stratagème': 0.005582393400482781,\n","  'requiert': 0.0018607978001609269,\n","  'ami': 0.0018607978001609269,\n","  'consigne': 0.0018607978001609269,\n","  'rue': 0.0037215956003218537,\n","  'lançant': 0.0018607978001609269,\n","  'fumigène': 0.0037215956003218537,\n","  'fenêtre': 0.0037215956003218537,\n","  'lorsque': 0.0037215956003218537,\n","  'ouverte': 0.0037215956003218537,\n","  'avant': 0.0003861504328211823,\n","  'criant': 0.0018607978001609269,\n","  'feu': 0.0037215956003218537,\n","  'compagnons': 0.0018607978001609269,\n","  'partent': 0.0018607978001609269,\n","  'ensemble': 0.0037215956003218537,\n","  'tarde': 0.0018607978001609269,\n","  'revenir': 0.0018607978001609269,\n","  'quelques': 0.0009303989000804634,\n","  'hommes': 0.0018607978001609269,\n","  'bousculent': 0.0018607978001609269,\n","  'ouvrir': 0.0037215956003218537,\n","  'porte': 0.0027911967002413906,\n","  'recevoir': 0.0009303989000804634,\n","  'pourboire': 0.0018607978001609269,\n","  'dispute': 0.0037215956003218537,\n","  'intervient': 0.0018607978001609269,\n","  'séparer': 0.0018607978001609269,\n","  'intervenants': 0.0018607978001609269,\n","  'reçoit': 0.0018607978001609269,\n","  'coup': 0.0,\n","  'visage': 0.0018607978001609269,\n","  'saignant': 0.0018607978001609269,\n","  'abondamment': 0.0018607978001609269,\n","  'emmené': 0.0018607978001609269,\n","  'allongé': 0.0018607978001609269,\n","  'canapé': 0.0037215956003218537,\n","  'salon': 0.005582393400482781,\n","  'reprendre': 0.0018607978001609269,\n","  'esprits': 0.0018607978001609269,\n","  'jouant': 0.0018607978001609269,\n","  'conviction': 0.0018607978001609269,\n","  'affirme': 0.0018607978001609269,\n","  'manquer': 0.0018607978001609269,\n","  'confié': 0.0018607978001609269,\n","  'crie': 0.0018607978001609269,\n","  'alertée': 0.0018607978001609269,\n","  'précipite': 0.0018607978001609269,\n","  'dirigeant': 0.0018607978001609269,\n","  'cachette': 0.007443191200643707,\n","  'dissimulée': 0.0018607978001609269,\n","  'derrière': 0.0018607978001609269,\n","  'panneau': 0.0018607978001609269,\n","  'récupérer': 0.0037215956003218537,\n","  'précieuse': 0.0018607978001609269,\n","  'repose': 0.0018607978001609269,\n","  'découvrant': 0.0018607978001609269,\n","  'fausse': 0.0018607978001609269,\n","  'alerte': 0.0018607978001609269,\n","  'repart': 0.0018607978001609269,\n","  'pu': 0.0018607978001609269,\n","  'cause': 0.0018607978001609269,\n","  'présence': 0.0009303989000804634,\n","  'autre': 0.0009303989000804634,\n","  'pièce': 0.004651994500402317,\n","  'convoité': 0.0018607978001609269,\n","  'toutefois': 0.0018607978001609269,\n","  'localisé': 0.0018607978001609269,\n","  'retrouve': 0.0037215956003218537,\n","  'tous': 0.0018607978001609269,\n","  'repartent': 0.0018607978001609269,\n","  'orchestré': 0.0018607978001609269,\n","  'complices': 0.0009303989000804634,\n","  'télégraphie': 0.0018607978001609269,\n","  'ensuite': 0.0009303989000804634,\n","  'langham': 0.0018607978001609269,\n","  'hotel': 0.0018607978001609269,\n","  'où': 0.0065127923005632435,\n","  'loge': 0.0018607978001609269,\n","  'demander': 0.0009303989000804634,\n","  'mettre': 0.0018607978001609269,\n","  'terme': 0.0018607978001609269,\n","  'comme': 0.0007723008656423646,\n","  'convenu': 0.0018607978001609269,\n","  'rendent': 0.0018607978001609269,\n","  'surprise': 0.0018607978001609269,\n","  'découvrir': 0.0018607978001609269,\n","  'lieux': 0.0018607978001609269,\n","  'courant': 0.0018607978001609269,\n","  'nuit': 0.0037215956003218537,\n","  'emportant': 0.0018607978001609269,\n","  'possessions': 0.0018607978001609269,\n","  'seule': 0.0018607978001609269,\n","  'domestique': 0.0018607978001609269,\n","  'reste': 0.0037215956003218537,\n","  'présente': 0.0018607978001609269,\n","  'fouille': 0.0018607978001609269,\n","  'trouvait': 0.0018607978001609269,\n","  'convoitée': 0.0018607978001609269,\n","  'découvre': 0.0009303989000804634,\n","  'intention': 0.0018607978001609269,\n","  'main': 0.0009303989000804634,\n","  'trouverez': 0.0018607978001609269,\n","  'nid': 0.0018607978001609269,\n","  'vide': 0.0018607978001609269,\n","  'viendrez': 0.0018607978001609269,\n","  'demain': 0.0018607978001609269,\n","  'quant': 0.0018607978001609269,\n","  'cesse': 0.0018607978001609269,\n","  'inquiéter': 0.0018607978001609269,\n","  'aimée': 0.0018607978001609269,\n","  'pourra': 0.0018607978001609269,\n","  'agir': 0.0018607978001609269,\n","  'bon': 0.0018607978001609269,\n","  'redouter': 0.0018607978001609269,\n","  'cruellement': 0.0018607978001609269,\n","  'offensée': 0.0018607978001609269,\n","  'compris': 0.0018607978001609269,\n","  'trahie': 0.0018607978001609269,\n","  'pouvait': 0.0009303989000804634,\n","  'jusqu': 0.0018607978001609269,\n","  'cœur': 0.0018607978001609269,\n","  'net': 0.0018607978001609269,\n","  'malgré': 0.0037215956003218537,\n","  'partiel': 0.0018607978001609269,\n","  'affaire': 0.0,\n","  'satisfait': 0.0018607978001609269,\n","  'message': 0.0018607978001609269,\n","  'garantit': 0.0018607978001609269,\n","  'rendue': 0.0018607978001609269,\n","  'accompagnée': 0.0018607978001609269,\n","  'récupère': 0.0018607978001609269,\n","  'mémoire': 0.0018607978001609269,\n","  'déjouée': 0.0018607978001609269,\n","  'adaptations': 0.0007723008656423646,\n","  'théâtre': 0.0018607978001609269,\n","  '1899': 0.0018607978001609269,\n","  'écrite': 0.0018607978001609269,\n","  'william': 0.0037215956003218537,\n","  'gillette': 0.0037215956003218537,\n","  'plusieurs': 0.0007723008656423646,\n","  'textes': 0.0037215956003218537,\n","  'canon': 0.0,\n","  'holmésien': 0.0009303989000804634,\n","  'laisse': 0.0018607978001609269,\n","  'croire': 0.0037215956003218537,\n","  'départ': 0.009303989000804634,\n","  'pousse': 0.0018607978001609269,\n","  'alice': 0.005582393400482781,\n","  'faulkner': 0.005582393400482781,\n","  'brent': 0.0018607978001609269,\n","  'traduction': 0.0009303989000804634,\n","  'française': 0.0018607978001609269,\n","  'lettres': 0.0018607978001609269,\n","  'compromettantes': 0.0018607978001609269,\n","  'éprouve': 0.0018607978001609269,\n","  'également': 0.0018607978001609269,\n","  'sentiments': 0.0037215956003218537,\n","  'miss': 0.0018607978001609269,\n","  'rappelant': 0.0018607978001609269,\n","  'envers': 0.0018607978001609269,\n","  'cinéma': 0.0009303989000804634,\n","  'télévision': 0.0009303989000804634,\n","  '1912': 0.0009303989000804634,\n","  'canine': 0.0018607978001609269,\n","  'incarné': 0.0018607978001609269,\n","  'chien': 0.0,\n","  'grièvement': 0.0018607978001609269,\n","  'blessé': 0.0037215956003218537,\n","  'devant': 0.0018607978001609269,\n","  'maison': 0.005582393400482781,\n","  'malfaiteur': 0.0009303989000804634,\n","  'souhaite': 0.0018607978001609269,\n","  'gouvernante': 0.0018607978001609269,\n","  'installer': 0.0018607978001609269,\n","  'faussement': 0.0018607978001609269,\n","  'permet': 0.0018607978001609269,\n","  'trouver': 0.0018607978001609269,\n","  'film': 0.001158451298463547,\n","  '1916': 0.0037215956003218537,\n","  'adapté': 0.0037215956003218537,\n","  'fidèle': 0.0018607978001609269,\n","  'inclut': 0.0009303989000804634,\n","  'notamment': 0.0037215956003218537,\n","  'réel': 0.0018607978001609269,\n","  'provoqué': 0.0018607978001609269,\n","  'lampe': 0.0018607978001609269,\n","  'pétrole': 0.0018607978001609269,\n","  'références': 0.0,\n","  'présentes': 0.0018607978001609269,\n","  'dressed': 0.0018607978001609269,\n","  'to': 0.0018607978001609269,\n","  'kill': 0.0018607978001609269,\n","  '1946': 0.0018607978001609269,\n","  'joué': 0.0037215956003218537,\n","  'basil': 0.0018607978001609269,\n","  'rathbone': 0.0018607978001609269,\n","  'parle': 0.0018607978001609269,\n","  'révèle': 0.0018607978001609269,\n","  'inadvertance': 0.0018607978001609269,\n","  'précieux': 0.0018607978001609269,\n","  'objet': 0.0018607978001609269,\n","  'situé': 0.0018607978001609269,\n","  'faux': 0.0018607978001609269,\n","  '1951': 0.0018607978001609269,\n","  'jouée': 0.0009303989000804634,\n","  'direct': 0.0037215956003218537,\n","  'bbc': 0.0018607978001609269,\n","  'six': 0.0018607978001609269,\n","  'épisodes': 0.0018607978001609269,\n","  'série': 0.0027030530297482763,\n","  'alan': 0.0018607978001609269,\n","  'wheatley': 0.0018607978001609269,\n","  'enregistrée': 0.0018607978001609269,\n","  'perdue': 0.0018607978001609269,\n","  'adaptée': 0.0037215956003218537,\n","  '1983': 0.0018607978001609269,\n","  'soviétique': 0.0018607978001609269,\n","  'intitulée': 0.0009303989000804634,\n","  'vassili': 0.0018607978001609269,\n","  'livanov': 0.0018607978001609269,\n","  'téléfilm': 0.0037215956003218537,\n","  'trésors': 0.0018607978001609269,\n","  'roman': 0.0018607978001609269,\n","  '1984': 0.0018607978001609269,\n","  'granada': 0.0018607978001609269,\n","  'television': 0.0018607978001609269,\n","  'jeremy': 0.0003861504328211823,\n","  'brett': 0.0003861504328211823,\n","  'premier': 0.0018607978001609269,\n","  'crime': 0.0018607978001609269,\n","  'the': 0.0,\n","  'royal': 0.0018607978001609269,\n","  'diffusé': 0.0018607978001609269,\n","  '2001': 0.0037215956003218537,\n","  'matt': 0.0018607978001609269,\n","  'frewer': 0.0018607978001609269,\n","  'plans': 0.0018607978001609269,\n","  'transposée': 0.0018607978001609269,\n","  'moderne': 0.0018607978001609269,\n","  '2012': 0.0037215956003218537,\n","  'buckingham': 0.0018607978001609269,\n","  'adaptation': 0.0003861504328211823,\n","  'bande': 0.0018607978001609269,\n","  'dessinée': 0.0018607978001609269,\n","  '2011': 0.0,\n","  'corée': 0.0018607978001609269,\n","  'sud': 0.0018607978001609269,\n","  'kwon': 0.0018607978001609269,\n","  'sous': 0.001158451298463547,\n","  'forme': 0.0018607978001609269,\n","  'manwha': 0.0018607978001609269,\n","  'story': 0.0037215956003218537,\n","  'vol': 0.0018607978001609269,\n","  '2': 0.0027911967002413906,\n","  'traduit': 0.0018607978001609269,\n","  'français': 0.0,\n","  'éditions': 0.0037215956003218537,\n","  'kwari': 0.0018607978001609269,\n","  'conservant': 0.0018607978001609269,\n","  'modernisation': 0.0018607978001609269,\n","  'relations': 0.0018607978001609269,\n","  'livre': 0.0,\n","  'audio': 0.0,\n","  'france': 0.0018607978001609269,\n","  'compagnie': 0.0,\n","  'savoir': 0.0,\n","  'récit': 0.0018607978001609269,\n","  'durée': 0.0,\n","  'minutes': 0.0018607978001609269,\n","  'narré': 0.0018607978001609269,\n","  'cyril': 0.0,\n","  'deguillen': 0.0,\n","  '3': 0.0009303989000804634,\n","  'postérité': 0.0037215956003218537,\n","  'permettant': 0.0018607978001609269,\n","  'repris': 0.0018607978001609269,\n","  'auteurs': 0.0018607978001609269,\n","  'jack': 0.0027911967002413906,\n","  'london': 0.005582393400482781,\n","  'texte': 0.0018607978001609269,\n","  'autobiographique': 0.0018607978001609269,\n","  'écrit': 0.0009303989000804634,\n","  'part': 0.0018607978001609269,\n","  'propres': 0.0018607978001609269,\n","  'écrits': 0.0018607978001609269,\n","  'smoke': 0.0018607978001609269,\n","  'bellew': 0.0018607978001609269,\n","  'scorbut': 0.0018607978001609269,\n","  'nombreuses': 0.0018607978001609269,\n","  'victimes': 0.0018607978001609269,\n","  'besoin': 0.0018607978001609269,\n","  'pommes': 0.005582393400482781,\n","  'crues': 0.0018607978001609269,\n","  'volé': 0.0018607978001609269,\n","  'toutes': 0.0018607978001609269,\n","  'eh': 0.0018607978001609269,\n","  'retrouvé': 0.0018607978001609269,\n","  'leurs': 0.0018607978001609269,\n","  'patates': 0.0018607978001609269,\n","  'employant': 0.0018607978001609269,\n","  'utilisé': 0.0009303989000804634,\n","  'mettent': 0.0009303989000804634,\n","  'voleur': 0.0037215956003218537,\n","  'fonce': 0.0018607978001609269,\n","  'sauve': 0.0018607978001609269,\n","  '4': 0.0009303989000804634,\n","  'connaît': 0.0018607978001609269,\n","  'dépassant': 0.0018607978001609269,\n","  'seules': 0.0018607978001609269,\n","  'américaine': 0.0018607978001609269,\n","  'carole': 0.0018607978001609269,\n","  'nelson': 0.0018607978001609269,\n","  'douglas': 0.0009303989000804634,\n","  'huit': 0.0009303989000804634,\n","  'parus': 0.0018607978001609269,\n","  '1990': 0.0018607978001609269,\n","  '2004': 0.0018607978001609269,\n","  'traduits': 0.0018607978001609269,\n","  'suite': 0.0037215956003218537,\n","  'bonne': 0.0018607978001609269,\n","  'mr': 0.0009303989000804634,\n","  'muse': 0.0018607978001609269,\n","  '2003': 0.0018607978001609269,\n","  'contre': 0.0009303989000804634,\n","  'irene': 0.0018607978001609269,\n","  '2005': 0.0018607978001609269,\n","  'dernière': 0.0018607978001609269,\n","  'valse': 0.0018607978001609269,\n","  '2007': 0.0018607978001609269,\n","  'apparaît': 0.0037215956003218537,\n","  'films': 0.0003861504328211823,\n","  'téléfilms': 0.0018607978001609269,\n","  'rapport': 0.0018607978001609269,\n","  'parmi': 0.0018607978001609269,\n","  'peuvent': 0.0018607978001609269,\n","  'cités': 0.0018607978001609269,\n","  'new': 0.0018607978001609269,\n","  'york': 0.0018607978001609269,\n","  '1976': 0.0018607978001609269,\n","  'charlotte': 0.0009303989000804634,\n","  'rampling': 0.0018607978001609269,\n","  'and': 0.0018607978001609269,\n","  'leading': 0.0018607978001609269,\n","  'lady': 0.0018607978001609269,\n","  '1992': 0.0018607978001609269,\n","  'traits': 0.0018607978001609269,\n","  'morgan': 0.0018607978001609269,\n","  'fairchild': 0.0018607978001609269,\n","  '2009': 0.0018607978001609269,\n","  'jeu': 0.0018607978001609269,\n","  'interprétée': 0.0009303989000804634,\n","  'rachel': 0.0018607978001609269,\n","  'mcadams': 0.0018607978001609269,\n","  'notes': 0.0,\n","  'premières': 0.0009303989000804634,\n","  'pages': 0.0009303989000804634,\n","  'précise': 0.0018607978001609269,\n","  'déroule': 0.0018607978001609269,\n","  'b': 0.0009303989000804634,\n","  'benedicte': 0.0018607978001609269,\n","  'critique': 0.0018607978001609269,\n","  't2': 0.0018607978001609269,\n","  'société': 0.0018607978001609269,\n","  '8': 0.0018607978001609269,\n","  '2013': 0.0018607978001609269,\n","  'référence': 0.0,\n","  'paris': 0.0,\n","  'coll': 0.0,\n","  'enquêtes': 0.0,\n","  'ean': 0.0,\n","  '3760002133423': 0.0018607978001609269,\n","  'bnf': 0.0,\n","  '42478151': 0.0018607978001609269,\n","  'détraqué': 0.0018607978001609269,\n","  'mésaventures': 0.0018607978001609269,\n","  '2017': 0.0009303989000804634,\n","  'aussi': 0.0,\n","  'autres': 0.0,\n","  'projets': 0.0,\n","  'wikimedia': 0.0,\n","  'commonsun': 0.0018607978001609269,\n","  'wikisource': 0.0,\n","  'connexes': 0.0,\n","  'liste': 0.0,\n","  'œuvres': 0.0,\n","  'liens': 0.0,\n","  'externes': 0.0,\n","  'ressources': 0.0018607978001609269,\n","  'relatives': 0.0018607978001609269,\n","  'littérature': 0.0,\n","  'internet': 0.0018607978001609269,\n","  'speculative': 0.0018607978001609269,\n","  'fiction': 0.0018607978001609269,\n","  'database': 0.0009303989000804634,\n","  'noosfere': 0.0018607978001609269,\n","  'illustré': 0.0018607978001609269,\n","  'ebooks': 0.0,\n","  'pdf': 0.0,\n","  'version': 0.0,\n","  'originale': 0.0,\n","  'v': 0.0,\n","  'mles': 0.0,\n","  'mystère': 0.0,\n","  'val': 0.0,\n","  'boscombe': 0.0,\n","  'pépins': 0.0,\n","  'lèvre': 0.0,\n","  'tordue': 0.0,\n","  'bleue': 0.0,\n","  'ruban': 0.0,\n","  'moucheté': 0.0,\n","  'pouce': 0.0,\n","  'aristocrate': 0.0,\n","  'célibataire': 0.0,\n","  'diadème': 0.0,\n","  'béryls': 0.0,\n","  'hêtres': 0.0,\n","  'rouges': 0.0,\n","  'mémoires': 0.0,\n","  'baskerville': 0.0,\n","  'retour': 0.0,\n","  'vallée': 0.0,\n","  'peur': 0.0,\n","  'dernier': 0.0,\n","  'archives': 0.0,\n","  'portail': 0.0,\n","  'polar': 0.0}}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# On calcule le tf-idf des textes de Sherlock\n","sherlock.tf_idf()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":2}
